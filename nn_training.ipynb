{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('data/kaggle_data/chessData.csv')\n",
    "data = pd.read_csv('chessdata_100k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEN</th>\n",
       "      <th>Evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR ...</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rnbqkbnr/pppp1ppp/4p3/8/4P3/8/PPPP1PPP/RNBQKBN...</td>\n",
       "      <td>+56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rnbqkbnr/pppp1ppp/4p3/8/3PP3/8/PPP2PPP/RNBQKBN...</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rnbqkbnr/ppp2ppp/4p3/3p4/3PP3/8/PPP2PPP/RNBQKB...</td>\n",
       "      <td>+52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rnbqkbnr/ppp2ppp/4p3/3p4/3PP3/8/PPPN1PPP/R1BQK...</td>\n",
       "      <td>-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 FEN Evaluation\n",
       "0  rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR ...        -10\n",
       "1  rnbqkbnr/pppp1ppp/4p3/8/4P3/8/PPPP1PPP/RNBQKBN...        +56\n",
       "2  rnbqkbnr/pppp1ppp/4p3/8/3PP3/8/PPP2PPP/RNBQKBN...         -9\n",
       "3  rnbqkbnr/ppp2ppp/4p3/3p4/3PP3/8/PPP2PPP/RNBQKB...        +52\n",
       "4  rnbqkbnr/ppp2ppp/4p3/3p4/3PP3/8/PPPN1PPP/R1BQK...        -26"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, board, score):\n",
    "        self.board = board\n",
    "        self.score = score\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.score)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # print(self.data[index])\n",
    "        board, score = self.board[index], self.score[index]\n",
    "\n",
    "        piece_val_map = {'p':-1,'k':-600,'b':-3,'r':-5,'q':-9,'n':-3,'P':1,'K':600,'B':3,'R':5,'Q':9,'N':3}\n",
    "\n",
    "        input_data = []\n",
    "        for char in board.split(\" \")[0]:\n",
    "            if char.isdigit():\n",
    "                for _ in range(int(char)):\n",
    "                    input_data.append(0)\n",
    "            else:\n",
    "                if char == '/':\n",
    "                    continue\n",
    "                input_data.append(piece_val_map[char])\n",
    "\n",
    "        if board.split(\" \")[1] == \"w\":\n",
    "            input_data.append(1)\n",
    "        else:\n",
    "            input_data.append(0)\n",
    "\n",
    "        if score.startswith(\"#\"):\n",
    "            score = score[1:]\n",
    "            \n",
    "        data = torch.tensor(input_data, dtype=torch.float32)\n",
    "        label = torch.tensor(int(score), dtype=torch.float32)\n",
    "\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChessDataset(data['FEN'], data['Evaluation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=128,\n",
    "                                         shuffle=True, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  -5.,    0.,    0.,    0.,    0.,   -5., -600.,    0.,   -1.,   -3.,\n",
      "           0.,    0.,   -9.,   -1.,   -1.,   -1.,    0.,   -1.,    0.,   -1.,\n",
      "          -3.,    0.,    0.,    0.,    0.,    0.,   -1.,    0.,   -1.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    1.,    1.,    0.,    0.,\n",
      "           0.,    3.,    1.,    1.,    3.,    0.,    9.,    0.,    1.,    1.,\n",
      "           0.,    0.,    0.,    0.,    1.,    1.,    0.,    0.,    0.,    5.,\n",
      "           0.,    5.,  600.,    0.,    0.])\n"
     ]
    }
   ],
   "source": [
    "for data in dataloader:\n",
    "    print(data[0][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(65, 1024)\n",
    "        self.hidden_layer = nn.Linear(1024, 512)\n",
    "        self.output_layer = nn.Linear(512, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.hidden_layer(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion, epochs, device):\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (data, target) in enumerate(dataloader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(data)\n",
    "\n",
    "            # Loss\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient descent\n",
    "            optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs} loss: {loss.item()} runnning_loss: {running_loss/len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvalNetwork(\n",
       "  (input_layer): Linear(in_features=65, out_features=1024, bias=True)\n",
       "  (hidden_layer): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (output_layer): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EvalNetwork()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dahiy_uokx4\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:530: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\dahiy_uokx4\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:530: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 loss: 2470269.75 runnning_loss: 3158.9127237851662\n",
      "Epoch 2/100 loss: 81602.265625 runnning_loss: 104.3507233056266\n",
      "Epoch 3/100 loss: 28883.37109375 runnning_loss: 36.935257153132994\n",
      "Epoch 4/100 loss: 30968.37109375 runnning_loss: 39.60149756234016\n",
      "Epoch 5/100 loss: 35819.234375 runnning_loss: 45.80464753836317\n",
      "Epoch 6/100 loss: 1998291.0 runnning_loss: 2555.359335038363\n",
      "Epoch 7/100 loss: 179781.9375 runnning_loss: 229.90017583120203\n",
      "Epoch 8/100 loss: 109786.828125 runnning_loss: 140.39236333120203\n",
      "Epoch 9/100 loss: 353121.0 runnning_loss: 451.5613810741688\n",
      "Epoch 10/100 loss: 18873.13671875 runnning_loss: 24.134445931905372\n",
      "Epoch 11/100 loss: 433084.6875 runnning_loss: 553.8167359335039\n",
      "Epoch 12/100 loss: 1172385.75 runnning_loss: 1499.2145140664961\n",
      "Epoch 13/100 loss: 81422.59375 runnning_loss: 104.12096387468031\n",
      "Epoch 14/100 loss: 79808.703125 runnning_loss: 102.05716512148338\n",
      "Epoch 15/100 loss: 130241.5625 runnning_loss: 166.54931265984655\n",
      "Epoch 16/100 loss: 461893.125 runnning_loss: 590.6561700767263\n",
      "Epoch 17/100 loss: 63744.15234375 runnning_loss: 81.51426130914322\n",
      "Epoch 18/100 loss: 58668.0546875 runnning_loss: 75.02308783567774\n",
      "Epoch 19/100 loss: 56848.6015625 runnning_loss: 72.696421435422\n",
      "Epoch 20/100 loss: 815743.75 runnning_loss: 1043.1505754475704\n",
      "Epoch 21/100 loss: 51396.1796875 runnning_loss: 65.72401494565217\n",
      "Epoch 22/100 loss: 135841.390625 runnning_loss: 173.7102181905371\n",
      "Epoch 23/100 loss: 32096.60546875 runnning_loss: 41.04425251758312\n",
      "Epoch 24/100 loss: 768533.75 runnning_loss: 982.7797314578005\n",
      "Epoch 25/100 loss: 77760.640625 runnning_loss: 99.43815936700767\n",
      "Epoch 26/100 loss: 143080.375 runnning_loss: 182.96723145780052\n",
      "Epoch 27/100 loss: 145255.796875 runnning_loss: 185.74910086317135\n",
      "Epoch 28/100 loss: 71768.1796875 runnning_loss: 91.77516584079284\n",
      "Epoch 29/100 loss: 67547.0 runnning_loss: 86.3772378516624\n",
      "Epoch 30/100 loss: 52276.890625 runnning_loss: 66.85024376598466\n",
      "Epoch 31/100 loss: 34405.6328125 runnning_loss: 43.99697290601023\n",
      "Epoch 32/100 loss: 974062.0 runnning_loss: 1245.6035805626598\n",
      "Epoch 33/100 loss: 61900.77734375 runnning_loss: 79.15700427589515\n",
      "Epoch 34/100 loss: 1132485.5 runnning_loss: 1448.1911764705883\n",
      "Epoch 35/100 loss: 1559272.875 runnning_loss: 1993.9550831202046\n",
      "Epoch 36/100 loss: 2127319.5 runnning_loss: 2720.3574168797954\n",
      "Epoch 37/100 loss: 42885.9296875 runnning_loss: 54.84134231138108\n",
      "Epoch 38/100 loss: 61304.07421875 runnning_loss: 78.3939568014706\n",
      "Epoch 39/100 loss: 22333.83203125 runnning_loss: 28.55988750799233\n",
      "Epoch 40/100 loss: 43231.2734375 runnning_loss: 55.28295835997442\n",
      "Epoch 41/100 loss: 16302.3896484375 runnning_loss: 20.84704558623721\n",
      "Epoch 42/100 loss: 101829.703125 runnning_loss: 130.21701166879797\n",
      "Epoch 43/100 loss: 23215.68359375 runnning_loss: 29.687574928069054\n",
      "Epoch 44/100 loss: 103148.890625 runnning_loss: 131.90395220588235\n",
      "Epoch 45/100 loss: 1201377.0 runnning_loss: 1536.2877237851662\n",
      "Epoch 46/100 loss: 55616.23046875 runnning_loss: 71.12049932065217\n",
      "Epoch 47/100 loss: 1036367.8125 runnning_loss: 1325.2785326086957\n",
      "Epoch 48/100 loss: 152087.71875 runnning_loss: 194.48557384910487\n",
      "Epoch 49/100 loss: 66303.4375 runnning_loss: 84.78700447570333\n",
      "Epoch 50/100 loss: 64097.109375 runnning_loss: 81.96561301150895\n",
      "Epoch 51/100 loss: 92189.609375 runnning_loss: 117.88952605498721\n",
      "Epoch 52/100 loss: 220639.71875 runnning_loss: 282.14797794117646\n",
      "Epoch 53/100 loss: 206125.59375 runnning_loss: 263.5877157928389\n",
      "Epoch 54/100 loss: 2028909.0 runnning_loss: 2594.512787723785\n",
      "Epoch 55/100 loss: 54972.3203125 runnning_loss: 70.29708479859335\n",
      "Epoch 56/100 loss: 116229.875 runnning_loss: 148.6315537084399\n",
      "Epoch 57/100 loss: 85867.4453125 runnning_loss: 109.80491727941177\n",
      "Epoch 58/100 loss: 47100.12109375 runnning_loss: 60.2303338794757\n",
      "Epoch 59/100 loss: 1702737.625 runnning_loss: 2177.4138427109974\n",
      "Epoch 60/100 loss: 48151.73828125 runnning_loss: 61.57511289162404\n",
      "Epoch 61/100 loss: 1284481.125 runnning_loss: 1642.558983375959\n",
      "Epoch 62/100 loss: 72279.046875 runnning_loss: 92.42844868925832\n",
      "Epoch 63/100 loss: 110146.4375 runnning_loss: 140.85222186700767\n",
      "Epoch 64/100 loss: 997562.25 runnning_loss: 1275.6550511508951\n",
      "Epoch 65/100 loss: 71673.109375 runnning_loss: 91.6535925511509\n",
      "Epoch 66/100 loss: 41922.109375 runnning_loss: 53.60883551790281\n",
      "Epoch 67/100 loss: 28697.09375 runnning_loss: 36.69705083120205\n",
      "Epoch 68/100 loss: 33119.421875 runnning_loss: 42.352201886189256\n",
      "Epoch 69/100 loss: 1009094.625 runnning_loss: 1290.4023337595909\n",
      "Epoch 70/100 loss: 171999.125 runnning_loss: 219.94773017902813\n",
      "Epoch 71/100 loss: 107663.375 runnning_loss: 137.67695012787723\n",
      "Epoch 72/100 loss: 33857.60546875 runnning_loss: 43.29617067615089\n",
      "Epoch 73/100 loss: 2590731.0 runnning_loss: 3312.955242966752\n",
      "Epoch 74/100 loss: 106624.1875 runnning_loss: 136.34806585677748\n",
      "Epoch 75/100 loss: 1118145.75 runnning_loss: 1429.8539002557545\n",
      "Epoch 76/100 loss: 58605.65625 runnning_loss: 74.94329443734016\n",
      "Epoch 77/100 loss: 17619.046875 runnning_loss: 22.53075047953964\n",
      "Epoch 78/100 loss: 252798.296875 runnning_loss: 323.2714793797954\n",
      "Epoch 79/100 loss: 47439.37109375 runnning_loss: 60.66415740888747\n",
      "Epoch 80/100 loss: 101137.890625 runnning_loss: 129.33234095268543\n",
      "Epoch 81/100 loss: 957828.5 runnning_loss: 1224.8446291560103\n",
      "Epoch 82/100 loss: 162983.78125 runnning_loss: 208.41915760869566\n",
      "Epoch 83/100 loss: 133486.125 runnning_loss: 170.6983695652174\n",
      "Epoch 84/100 loss: 117779.765625 runnning_loss: 150.61351102941177\n",
      "Epoch 85/100 loss: 933174.0625 runnning_loss: 1193.3172154731458\n",
      "Epoch 86/100 loss: 937700.25 runnning_loss: 1199.105179028133\n",
      "Epoch 87/100 loss: 81331.90625 runnning_loss: 104.00499520460357\n",
      "Epoch 88/100 loss: 63686.87109375 runnning_loss: 81.44101162883632\n",
      "Epoch 89/100 loss: 1229349.625 runnning_loss: 1572.0583439897698\n",
      "Epoch 90/100 loss: 155068.84375 runnning_loss: 198.29775415601023\n",
      "Epoch 91/100 loss: 44681.5 runnning_loss: 57.137468030690535\n",
      "Epoch 92/100 loss: 38450.2421875 runnning_loss: 49.169107656649615\n",
      "Epoch 93/100 loss: 165849.875 runnning_loss: 212.08423913043478\n",
      "Epoch 94/100 loss: 1170228.75 runnning_loss: 1496.4562020460357\n",
      "Epoch 95/100 loss: 66437.1875 runnning_loss: 84.95804028132993\n",
      "Epoch 96/100 loss: 1010220.9375 runnning_loss: 1291.8426310741688\n",
      "Epoch 97/100 loss: 1185066.0 runnning_loss: 1515.4296675191815\n",
      "Epoch 98/100 loss: 82049.0703125 runnning_loss: 104.92208479859335\n",
      "Epoch 99/100 loss: 178096.34375 runnning_loss: 227.7446851023018\n",
      "Epoch 100/100 loss: 1471438.75 runnning_loss: 1881.6352301790282\n"
     ]
    }
   ],
   "source": [
    "# create the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# create the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# num of epochs\n",
    "epochs = 100\n",
    "\n",
    "# train the model\n",
    "train(model, dataloader,  optimizer, criterion,epochs, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_eval = model.forward(torch.tensor([0.,0.,0.,0.,-5.,   -3., -600.,    0.,    0.,    0.,\n",
    "          -1.,   -9.,    0.,   -1.,   -1.,    0.,   -1.,    0.,   -3.,    0.,\n",
    "          -5.,    0.,    0.,   -1.,    0.,   -1.,    0.,    0.,    0.,    0.,\n",
    "           0.,    0.,    0.,    1.,    0.,    0.,    3.,   -1.,    0.,    0.,\n",
    "           1.,    0.,    1.,    1.,    0.,    3.,    0.,    0.,    0.,    0.,\n",
    "           9.,    0.,    0.,    1.,    1.,    1.,    5.,    0.,    0.,    5.,\n",
    "           0.,    0.,  600.,    0.,    0.], dtype=torch.float32).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([29.9571], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model/nn_1024_512.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvalNetwork(\n",
       "  (input_layer): Linear(in_features=65, out_features=1024, bias=True)\n",
       "  (hidden_layer): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (output_layer): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.output_layer.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
