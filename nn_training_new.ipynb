{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('data/kaggle_data/chessData.csv')\n",
    "data = pd.read_csv('data/chessdata_500k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEN</th>\n",
       "      <th>Evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR ...</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rnbqkbnr/pppp1ppp/4p3/8/4P3/8/PPPP1PPP/RNBQKBN...</td>\n",
       "      <td>+56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rnbqkbnr/pppp1ppp/4p3/8/3PP3/8/PPP2PPP/RNBQKBN...</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rnbqkbnr/ppp2ppp/4p3/3p4/3PP3/8/PPP2PPP/RNBQKB...</td>\n",
       "      <td>+52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rnbqkbnr/ppp2ppp/4p3/3p4/3PP3/8/PPPN1PPP/R1BQK...</td>\n",
       "      <td>-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 FEN Evaluation\n",
       "0  rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR ...        -10\n",
       "1  rnbqkbnr/pppp1ppp/4p3/8/4P3/8/PPPP1PPP/RNBQKBN...        +56\n",
       "2  rnbqkbnr/pppp1ppp/4p3/8/3PP3/8/PPP2PPP/RNBQKBN...         -9\n",
       "3  rnbqkbnr/ppp2ppp/4p3/3p4/3PP3/8/PPP2PPP/RNBQKB...        +52\n",
       "4  rnbqkbnr/ppp2ppp/4p3/3p4/3PP3/8/PPPN1PPP/R1BQK...        -26"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fen_to_bit_vector(fen):\n",
    "    parts = fen.split(' ')\n",
    "    piece_placement = parts[0].split('/')\n",
    "    active_color = parts[1]\n",
    "    castling_rights = parts[2]\n",
    "    en_passant = parts[3]\n",
    "    halfmove_clock = int(parts[4])\n",
    "    fullmove_clock = int(parts[5])\n",
    "\n",
    "    bit_vector = np.zeros((13, 8, 8), dtype=np.uint8)\n",
    "    \n",
    "    # piece to layer structure taken from reference [1]\n",
    "    piece_to_layer = {\n",
    "        'R': 1,'N': 2,'B': 3,'Q': 4,'K': 5,'P': 6,'p': 7,'k': 8,\n",
    "        'q': 9,'b': 10,'n': 11,'r': 12\n",
    "    }\n",
    "    \n",
    "    castling = {'K': (7,7),'Q': (7,0),'k': (0,7),'q': (0,0),}\n",
    "\n",
    "    for r, row in enumerate(piece_placement):\n",
    "        c = 0\n",
    "        for piece in row:\n",
    "            if piece in piece_to_layer:\n",
    "                bit_vector[piece_to_layer[piece], r, c] = 1\n",
    "                c += 1\n",
    "            else:\n",
    "                c += int(piece)\n",
    "    \n",
    "    if en_passant != '-':\n",
    "        bit_vector[0, ord(en_passant[0]) - ord('a'), int(en_passant[1]) - 1] = 1\n",
    "    \n",
    "    if castling_rights != '-':\n",
    "        for char in castling_rights:\n",
    "            bit_vector[0, castling[char][0], castling[char][1]] = 1\n",
    "    \n",
    "    if active_color == 'w':\n",
    "        bit_vector[0, 7, 4] = 1\n",
    "    else:\n",
    "        bit_vector[0, 0, 4] = 1\n",
    "\n",
    "    if halfmove_clock > 0:\n",
    "        c = 7\n",
    "        while halfmove_clock > 0:\n",
    "            bit_vector[0, 3, c] = halfmove_clock%2\n",
    "            halfmove_clock = halfmove_clock // 2\n",
    "            c -= 1\n",
    "            if c < 0:\n",
    "                break\n",
    "\n",
    "    if fullmove_clock > 0:\n",
    "        c = 7\n",
    "        while fullmove_clock > 0:\n",
    "            bit_vector[0, 4, c] = fullmove_clock%2\n",
    "            fullmove_clock = fullmove_clock // 2\n",
    "            c -= 1\n",
    "            if c < 0:\n",
    "                break\n",
    "\n",
    "    return bit_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, fen_board, score):\n",
    "        self.fen_board = fen_board\n",
    "        self.score = score\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.score)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # print(self.data[index])\n",
    "        fen_board, score = self.fen_board[index], self.score[index]\n",
    "        \n",
    "        piece_boards = fen_to_bit_vector(fen_board)\n",
    "\n",
    "        \n",
    "        score= score.replace('\\ufeff', '')\n",
    "        try:\n",
    "            score = int(score)\n",
    "        except ValueError:\n",
    "            score = 10000 if score[1] == '+' else -10000\n",
    "        score = score / 100\n",
    "            \n",
    "        \n",
    "        data = torch.tensor(piece_boards, dtype=torch.float32)\n",
    "        label = torch.tensor(int(score), dtype=torch.float32)\n",
    "\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChessDataset(data['FEN'], data['Evaluation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32,\n",
    "                                         shuffle=True, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 1.],\n",
      "         [0., 0., 0., 1., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 1., 1., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 1., 1., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "         [1., 0., 0., 0., 0., 1., 1., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 1., 1., 1.],\n",
      "         [1., 1., 0., 1., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "for data in dataloader:\n",
    "    print(data[0][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(832, 832)\n",
    "        self.hidden_layer1 = nn.Linear(832, 416)\n",
    "        self.hidden_layer2 = nn.Linear(416, 218)\n",
    "        self.hidden_layer3 = nn.Linear(218, 104)\n",
    "        self.output_layer = nn.Linear(104, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.input_layer(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.hidden_layer1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.hidden_layer2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.hidden_layer3(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion, epochs, device):\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (data, target) in enumerate(dataloader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(data)\n",
    "\n",
    "            # Loss\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient descent\n",
    "            optimizer.step()\n",
    "        \n",
    "            running_loss += loss.item()\n",
    "            if i%5000 == 4999:\n",
    "                print('Epoch %d, %5d : loss %.4f'%(epoch+1, i+1, running_loss/(5000*len(data))))\n",
    "                running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvalNetwork(\n",
       "  (input_layer): Linear(in_features=832, out_features=832, bias=True)\n",
       "  (hidden_layer1): Linear(in_features=832, out_features=416, bias=True)\n",
       "  (hidden_layer2): Linear(in_features=416, out_features=218, bias=True)\n",
       "  (hidden_layer3): Linear(in_features=218, out_features=104, bias=True)\n",
       "  (output_layer): Linear(in_features=104, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EvalNetwork()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dahiy_uokx4\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:530: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1,  5000 : loss 4.6519\n",
      "Epoch 1, 10000 : loss 4.5714\n",
      "Epoch 1, 15000 : loss 4.6082\n",
      "Epoch 2,  5000 : loss 4.6517\n",
      "Epoch 2, 10000 : loss 4.6372\n",
      "Epoch 2, 15000 : loss 4.5205\n",
      "Epoch 3,  5000 : loss 4.6376\n",
      "Epoch 3, 10000 : loss 4.6218\n",
      "Epoch 3, 15000 : loss 4.6052\n",
      "Epoch 4,  5000 : loss 4.5799\n",
      "Epoch 4, 10000 : loss 4.6800\n",
      "Epoch 4, 15000 : loss 4.5701\n",
      "Epoch 5,  5000 : loss 4.6423\n",
      "Epoch 5, 10000 : loss 4.5161\n",
      "Epoch 5, 15000 : loss 4.6379\n",
      "Epoch 6,  5000 : loss 4.6451\n",
      "Epoch 6, 10000 : loss 4.6306\n",
      "Epoch 6, 15000 : loss 4.5658\n",
      "Epoch 7,  5000 : loss 4.4794\n",
      "Epoch 7, 10000 : loss 4.7601\n",
      "Epoch 7, 15000 : loss 4.6408\n",
      "Epoch 8,  5000 : loss 4.6938\n",
      "Epoch 8, 10000 : loss 4.5801\n",
      "Epoch 8, 15000 : loss 4.5553\n",
      "Epoch 9,  5000 : loss 4.6234\n",
      "Epoch 9, 10000 : loss 4.5695\n",
      "Epoch 9, 15000 : loss 4.6085\n",
      "Epoch 10,  5000 : loss 4.6096\n",
      "Epoch 10, 10000 : loss 4.5311\n",
      "Epoch 10, 15000 : loss 4.6965\n"
     ]
    }
   ],
   "source": [
    "# create the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# create the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# num of epochs\n",
    "epochs = 10\n",
    "\n",
    "# train the model\n",
    "loss_list = train(model, dataloader,  optimizer, criterion,epochs, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model/cnn_1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.output_layer.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
